# Paper-Thinking-on-Visual-Captioning

This repo focus on Image/Video Caption &amp; Seq-to-Seq Learning &amp; NLP

![recent_read](paper_thinking.png)

# Paper Thinking

## Image Caption

### Model

- Exploring Visual Relationship for Image Captioning.(ECCV2018)
- Show, Tell and Discriminate: Image Captioning by Self-retrieval with Partially Labeled Data.(ECCV2018)
- “Factual” or “emotional”: Stylized image captioning with adaptive learning and attention.(ECCV2018)
- Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering.(CVPR2018)
- Neural Baby Talk.(CVPR2018)
- Knowing When to Look: Adaptive Attention via A Visual Sentinel for Image Captioning.(CVPR2017)
- Show, Attend and Tell: Neural Image Caption Generation with Visual Attention.(ICML2015)

### Training Strategy

- Self-critical sequence training for image captioning.(CVPR2017)

### Evaluation

- NNEval : Neural Network based Evaluation Metric for Image Captioning.(ECCV2018)
- Improved Image Captioning via Policy Gradient optimization of SPIDEr.(ICCV2017)

## Arxiv Update

- Viewpoint Invariant Change Captioning
- Not All Words are Equal : Video-specific Information Loss for Video Captioning
- Hierarchical LSTMs with Adaptive Attention for Visual Captioning

## NLP

- Attention is all you need

## Video Caption

- Less Is More: Picking Informative Frames for Video Captioning(ECCV2018)
- Modeling Embedding and Translation to Bridge Video and Language(CVPR2016)
- Video Captioning via Hierarchical Reinforcement Learning(CVPR2018)

## New Idea

- CONNECTING IMAGES AND NATURAL LANGUAGE ADISSERTATION(Andrej Karpathy)
- Sequence Level Training with Recurrent Neural Networks(ICML2015)
