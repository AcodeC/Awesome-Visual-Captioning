# Paper-Thinking-on-Visual-Captioning

This repo focus on Image/Video Caption &amp; Seq-to-Seq Learning &amp; NLP

![recent_read](./paper_thinking.png)

# Paper Thinking

## Image Caption

### Model

- Exploring Visual Relationship for Image Captioning.(ECCV2018)
- Show, Tell and Discriminate: Image Captioning by Self-retrieval with Partially Labeled Data.(ECCV2018)
- “Factual” or “emotional”: Stylized image captioning with adaptive learning and attention.(ECCV2018)
- Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering.(**Peter Anderson**, CVPR2018)
- Neural Baby Talk.(CVPR2018)
- Knowing When to Look: Adaptive Attention via A Visual Sentinel for Image Captioning.(CVPR2017)
- Show, Attend and Tell: Neural Image Caption Generation with Visual Attention.(ICML2015)

### Training Strategy

- Self-critical sequence training for image captioning.(CVPR2017)
- Sequence-to-Sequence Learning as Beam-Search Optimization

### Evaluation

- NNEval : Neural Network based Evaluation Metric for Image Captioning.(ECCV2018)
- Improved Image Captioning via Policy Gradient optimization of SPIDEr.(ICCV2017)

## Arxiv Update

- Viewpoint Invariant Change Captioning
- Not All Words are Equal : Video-specific Information Loss for Video Captioning(Jiarong Dong)
- Hierarchical LSTMs with Adaptive Attention for Visual Captioning

## NLP

- Attention is all you need([The Annotated Transformer](http://nlp.seas.harvard.edu/2018/04/03/attention.html), [The Illustrated Transformer](http://jalammar.github.io/illustrated-transformer/), [Transformer on ImgCaption](https://github.com/ruotianluo/Transformer_Captioning/blob/master/train.py))
- Latent Alignment and Variational Attention(VAE, [paper](https://arxiv.org/pdf/1807.03756.pdf))
- Variational Neural Machine Translation(VAE for NMT, [paper](https://arxiv.org/pdf/1605.07869.pdf))
- Variational Recurrent Neural Machine Translation(VAE for NMT, [paper](https://arxiv.org/pdf/1801.05119.pdf))

## Video Caption

- Temporal Deformable Convolutional Encoder-Decoder Networks for Video Captioning(AAAI2019 **oral**, [paper](http://home.ustc.edu.cn/~panywei/paper/AAAI19.2277.pdf))
- Less Is More: Picking Informative Frames for Video Captioning(ECCV2018)
- Modeling Embedding and Translation to Bridge Video and Language(CVPR2016)
- Video Captioning via Hierarchical Reinforcement Learning(CVPR2018)

## New Idea

- Detecting and Recognizing Human-Object Interactions(**Ross Girshick**, **Piotr Dollar**, **Kaiming He**, [paper](https://arxiv.org/pdf/1704.07333.pdf))
- CONNECTING IMAGES AND NATURAL LANGUAGE ADISSERTATION(**Andrej Karpathy**)
- Sequence Level Training with Recurrent Neural Networks(ICML2015)
- Deep Feature Flow for Video Recognition(CVPR2017, video object detection, [code.mxnet](https://github.com/msracver/Deep-Feature-Flow), [FlowNet2.pytorch](https://github.com/NVIDIA/flownet2-pytorch))
- Conceptual Captions: A Cleaned, Hypernymed, Image Alt-text Dataset For Automatic Image Captioning(ACL2018, New dataset but not release)

