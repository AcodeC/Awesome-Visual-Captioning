# Awesome-Visual-Captioning[![Awesome](https://awesome.re/badge.svg)](https://awesome.re)

<p align="center">
  <img width="250" src="https://camo.githubusercontent.com/1131548cf666e1150ebd2a52f44776d539f06324/68747470733a2f2f63646e2e7261776769742e636f6d2f73696e647265736f726875732f617765736f6d652f6d61737465722f6d656469612f6c6f676f2e737667" "Awesome!">
</p>

A curated list of image captioning and video captioning and related area. :-)
***
This repository focus on Image Captioning & Video Captioning &amp; Seq-to-Seq Learning &amp; NLP

## Newly update! AAAI-2020
**Image Captioning**
- **Unified VLP**: Luowei Zhou (University of Michigan)*; Hamid Palangi (Microsoft Research); Lei Zhang (Microsoft); Houdong Hu
(Microsoft AI and Research); Jason Corso (University of Michigan); Jianfeng Gao (Microsoft Research)  
"[Unified Vision-Language Pre-Training for Image Captioning and VQA](https://arxiv.org/abs/1909.11059)". `AAAI 2020`  

- **OffPG**: Paul Hongsuck Seo (POSTECH)*; Piyush Sharma (Google Research); Tomer Levinboim (Google); Bohyung Han
(Seoul National University); Radu Soricut (Google)  
"[Reinforcing an Image Caption Generator using Off-line Human Feedback](https://arxiv.org/abs/1911.09753)". `AAAI 2020`  

- **MemCap**: Wentian Zhao (Beijing Institute of Technology); Xinxiao Wu (Beijing Institute of Technology)*; Xiaoxun Zhang
(Alibaba Group)  
"[MemCap: Memorizing Style Knowledge for Image Captioning](https://wuxinxiao.github.io/assets/papers/2020/MemCap.pdf)". `AAAI 2020`  

- **C-R Reasoning**: Jingyi Hou (Beijing Institute of Technology); Xinxiao Wu (Beijing Institute of Technology)*; Xiaoxun Zhang (Alibaba
Group); Yayun Qi (Beijing Institute of Technology); Yunde Jia (Beijing Institute of Technology); Jiebo Luo (University
of Rochester)  
"[Joint Commonsense and Relation Reasoning for Image and Video Captioning](https://wuxinxiao.github.io/assets/papers/2020/C-R_reasoning.pdf)". `AAAI 2020`  

- **unknown**: Wei Zhang (East China Normal University)*; Yue Ying (East China Normal University); Pan Lu (The University of
California, Los Angeles); Hongyuan Zha (GEORGIA TECH)  
"Learning Long- and Short-Term User Literal-Preference with Multimodal Hierarchical Transformer Network
for Personalized Image Caption". `AAAI 2020`  

- **unknown**: Li WANG (MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University, China)*; Zechen BAI
(Institute of Software, Chinese Academy of Science, China); Yonghua Zhang (Bytedance); Hongtao Lu (Shanghai Jiao
Tong University)   
"Show, Recall, and Tell: Image Captioning with Recall Mechanism". `AAAI 2020`  

- **unknown**: Junhao Liu (Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences); Kai Wang (Shenzhen
Institutes of Advanced Technology, Chinese Academy of Sciences); Chunpu Xu (Huazhong University of Science and
Technology); Zhou Zhao (Zhejiang University); Ruifeng Xu (Harbin Institute of Technology (Shenzhen)); Ying Shen
(Peking University Shenzhen Graduate School); Min Yang ( Chinese Academy of Sciences)*    
"Interactive Dual Generative Adversarial Networks for Image Captioning". `AAAI 2020`  

- **unknown**: Tingjia Cao (Fudan University)*; Ke Han (Fudan University); Xiaomei Wang (Fudan University); Lin Ma (Tencent AI
Lab); Yanwei Fu (Fudan University); Yu-Gang Jiang (Fudan University); Xiangyang Xue (Fudan University)     
"Feature Deformation Meta-Networks in Image Captioning of Novel Objects". `AAAI 2020`  

**Video Captioning** 
- **unknown**: Maitreya Suin (Indian Institute of Technology Madras)*; Rajagopalan Ambasamudram (Indian Institute of
Technology Madras)  
"An Efficient Framework for Dense Video Captioning". `AAAI 2020`  

## Newly update! NeurIPS-2019
**Image Captioning**
- **AAT**: Lun Huang, Wenmin Wang, Yaxian Xia, Jie Chen  
"[Adaptively Aligned Image Captioning via Adaptive Attention Time](http://papers.nips.cc/paper/by-source-2019-4799)". `NeurIPS 2019` [[code]](https://github.com/husthuaan/AAT)

- **VSSI-cap**: Fuhai Chen, Rongrong Ji, Jiayi Ji, Xiaoshuai Sun, Baochang Zhang, Xuri Ge, Yongjian Wu, Feiyue Huang  
"[Variational Structured Semantic Inference for Diverse Image Captioning](http://papers.nips.cc/paper/by-source-2019-1113)". `NeurIPS 2019`  

- **ObjRel Transf**: Simao Herdade, Armin Kappeler, Kofi Boakye, Joao Soares  
"[Image Captioning: Transforming Objects into Words](http://papers.nips.cc/paper/by-source-2019-5963)". `NeurIPS 2019` [[code]](https://github.com/yahoo/object_relation_transformer)  


## ICCV-2019
**Video Captioning**  
- **VATEX**: Xin Wang, Jiawei Wu, Junkun Chen, Lei Li, Yuan-Fang Wang, William Yang Wang  
"[VaTeX: A Large-Scale, High-Quality Multilingual Dataset for Video-and-Language Research](http://openaccess.thecvf.com/content_ICCV_2019/papers/Wang_VaTeX_A_Large-Scale_High-Quality_Multilingual_Dataset_for_Video-and-Language_Research_ICCV_2019_paper.pdf)". `ICCV 2019`   

- **POS+CG**: Bairui Wang, Lin Ma, Wei Zhang, Wenhao Jiang, Jingwen Wang, Wei Liu  
"[Controllable Video Captioning With POS Sequence Guidance Based on Gated Fusion Network](http://openaccess.thecvf.com/content_ICCV_2019/papers/Wang_Controllable_Video_Captioning_With_POS_Sequence_Guidance_Based_on_Gated_ICCV_2019_paper.pdf)". `ICCV 2019`  

- **POS**: Jingyi Hou, Xinxiao Wu, Wentian Zhao, Jiebo Luo, Yunde Jia  
"[Joint Syntax Representation Learning and Visual Cue Translation for Video Captioning](http://openaccess.thecvf.com/content_ICCV_2019/papers/Hou_Joint_Syntax_Representation_Learning_and_Visual_Cue_Translation_for_Video_ICCV_2019_paper.pdf)". `ICCV 2019`  

**Image Captioning**   
- **MaBi-LSTMs**: Hongwei Ge, Zehang Yan, Kai Zhang, Mingde Zhao, Liang Sun  
"[Exploring Overall Contextual Information for Image Captioning in Human-Like Cognitive Style](http://openaccess.thecvf.com/content_ICCV_2019/papers/Ge_Exploring_Overall_Contextual_Information_for_Image_Captioning_in_Human-Like_Cognitive_ICCV_2019_paper.pdf)". `ICCV 2019`  

- **Align2Ground**: Samyak Datta, Karan Sikka, Anirban Roy, Karuna Ahuja, Devi Parikh, Ajay Divakaran    
"[Align2Ground: Weakly Supervised Phrase Grounding Guided by Image-Caption Alignment](http://openaccess.thecvf.com/content_ICCV_2019/papers/Datta_Align2Ground_Weakly_Supervised_Phrase_Grounding_Guided_by_Image-Caption_Alignment_ICCV_2019_paper.pdf)". `ICCV 2019`  

- **GCN-LSTM+HIP**: Ting Yao, Yingwei Pan, Yehao Li, Tao Mei   
"[Hierarchy Parsing for Image Captioning](http://openaccess.thecvf.com/content_ICCV_2019/papers/Yao_Hierarchy_Parsing_for_Image_Captioning_ICCV_2019_paper.pdf)". `ICCV 2019`  

- **IR+Tdiv**: Lixin Liu, Jiajun Tang, Xiaojun Wan, Zongming Guo    
"[Generating Diverse and Descriptive Image Captions Using Visual Paraphrases](http://openaccess.thecvf.com/content_ICCV_2019/papers/Liu_Generating_Diverse_and_Descriptive_Image_Captions_Using_Visual_Paraphrases_ICCV_2019_paper.pdf)". `ICCV 2019`  

- **CNM+SGAE**: Xu Yang, Hanwang Zhang, Jianfei Cai    
"[Learning to Collocate Neural Modules for Image Captioning](http://openaccess.thecvf.com/content_ICCV_2019/papers/Yang_Learning_to_Collocate_Neural_Modules_for_Image_Captioning_ICCV_2019_paper.pdf)". `ICCV 2019`  

- **Seq-CVAE**: Jyoti Aneja, Harsh Agrawal, Dhruv Batra, Alexander Schwing    
"[Sequential Latent Spaces for Modeling the Intention During Diverse Image Captioning](http://openaccess.thecvf.com/content_ICCV_2019/papers/Aneja_Sequential_Latent_Spaces_for_Modeling_the_Intention_During_Diverse_Image_ICCV_2019_paper.pdf)". `ICCV 2019`  

- **DUDA**: Dong Huk Park, Trevor Darrell, Anna Rohrbach   
"[Robust Change Captioning](http://openaccess.thecvf.com/content_ICCV_2019/papers/Park_Robust_Change_Captioning_ICCV_2019_paper.pdf)". `ICCV 2019`  

- **AoANet**: Lun Huang, Wenmin Wang, Jie Chen, Xiao-Yong Wei   
"[Attention on Attention for Image Captioning](http://openaccess.thecvf.com/content_ICCV_2019/papers/Huang_Attention_on_Attention_for_Image_Captioning_ICCV_2019_paper.pdf)". `ICCV 2019`  

- : Iro Laina, Christian Rupprecht, Nassir Navab   
"[Towards Unsupervised Image Captioning With Shared Multimodal Embeddings](http://openaccess.thecvf.com/content_ICCV_2019/papers/Laina_Towards_Unsupervised_Image_Captioning_With_Shared_Multimodal_Embeddings_ICCV_2019_paper.pdf)". `ICCV 2019`  

- : Sen He, Hamed R. Tavakoli, Ali Borji, Nicolas Pugeault   
"[Human Attention in Image Captioning: Dataset and Analysis](http://openaccess.thecvf.com/content_ICCV_2019/papers/He_Human_Attention_in_Image_Captioning_Dataset_and_Analysis_ICCV_2019_paper.pdf)". `ICCV 2019`  

- **RDN**: Lei Ke, Wenjie Pei, Ruiyu Li, Xiaoyong Shen, Yu-Wing Tai   
"[Reflective Decoding Network for Image Captioning](http://openaccess.thecvf.com/content_ICCV_2019/papers/Ke_Reflective_Decoding_Network_for_Image_Captioning_ICCV_2019_paper.pdf)". `ICCV 2019`  

- **PSST**: Gilad Vered, Gal Oren, Yuval Atzmon, Gal Chechik   
"[Joint Optimization for Cooperative Image Captioning](http://openaccess.thecvf.com/content_ICCV_2019/papers/Vered_Joint_Optimization_for_Cooperative_Image_Captioning_ICCV_2019_paper.pdf)". `ICCV 2019`  

- **MUTAN**: Tanzila Rahman, Bicheng Xu, Leonid Sigal   
"[Watch, Listen and Tell: Multi-Modal Weakly Supervised Dense Event Captioning](http://openaccess.thecvf.com/content_ICCV_2019/papers/Rahman_Watch_Listen_and_Tell_Multi-Modal_Weakly_Supervised_Dense_Event_Captioning_ICCV_2019_paper.pdf)". `ICCV 2019`  

- **ETA**: Guang Li, Linchao Zhu, Ping Liu, Yi Yang   
"[Entangled Transformer for Image Captioning](http://openaccess.thecvf.com/content_ICCV_2019/papers/Li_Entangled_Transformer_for_Image_Captioning_ICCV_2019_paper.pdf)". `ICCV 2019`  

- **nocaps**: Harsh Agrawal, Karan Desai, Yufei Wang, Xinlei Chen, Rishabh Jain, Mark Johnson, Dhruv Batra, Devi Parikh, Stefan Lee, Peter Anderson   
"[nocaps: novel object captioning at scale](http://openaccess.thecvf.com/content_ICCV_2019/papers/Agrawal_nocaps_novel_object_captioning_at_scale_ICCV_2019_paper.pdf)". `ICCV 2019`  

- : Keren Ye, Mingda Zhang, Adriana Kovashka, Wei Li, Danfeng Qin, Jesse Berent   
"[Cap2Det: Learning to Amplify Weak Caption Supervision for Object Detection](http://openaccess.thecvf.com/content_ICCV_2019/papers/Ye_Cap2Det_Learning_to_Amplify_Weak_Caption_Supervision_for_Object_Detection_ICCV_2019_paper.pdf)". `ICCV 2019`  

- **Graph-Align**: Jiuxiang Gu, Shafiq Joty, Jianfei Cai, Handong Zhao, Xu Yang, Gang Wang   
"[Unpaired Image Captioning via Scene Graph Alignments](http://openaccess.thecvf.com/content_ICCV_2019/papers/Gu_Unpaired_Image_Captioning_via_Scene_Graph_Alignments_ICCV_2019_paper.pdf)". `ICCV 2019`  

- : Tingke Shen, Amlan Kar, Sanja Fidler   
"[Learning to Caption Images Through a Lifetime by Asking Questions](http://openaccess.thecvf.com/content_ICCV_2019/papers/Shen_Learning_to_Caption_Images_Through_a_Lifetime_by_Asking_Questions_ICCV_2019_paper.pdf)". `ICCV 2019`  

## CVPR-2019
**Image Captioning**  
- :XU YANG (Nanyang Technological University)*; Kaihua Tang (Nanyang Technological University); Hanwang Zhang (Nanyang Technological University); Jianfei Cai (Nanyang Technological University)  
"[Auto-Encoding Scene Graphs for Image Captioning](http://openaccess.thecvf.com/content_CVPR_2019/papers/Yang_Auto-Encoding_Scene_Graphs_for_Image_Captioning_CVPR_2019_paper.pdf)". `CVPR 2019 Oral` [[code]](https://github.com/fengyang0317/unsupervised_captioning)

- :Aditya Deshpande (University of Illinois at UC)*; Jyoti Aneja (University of Illinois, Urbana-Champaign); Liwei Wang (Tencent AI Lab); Alexander Schwing (UIUC); David Forsyth (Univeristy of Illinois at Urbana-Champaign)  
"[Fast, Diverse and Accurate Image Captioning Guided by Part-Of-Speech](http://openaccess.thecvf.com/content_CVPR_2019/papers/Deshpande_Fast_Diverse_and_Accurate_Image_Captioning_Guided_by_Part-Of-Speech_CVPR_2019_paper.pdf)". `CVPR 2019 Oral`

- :Yang Feng (University of Rochester)*; Lin Ma (Tencent AI Lab); Wei Liu (Tencent); Jiebo Luo (U. Rochester)  
"[Unsupervised Image Captioning](http://openaccess.thecvf.com/content_CVPR_2019/papers/Feng_Unsupervised_Image_Captioning_CVPR_2019_paper.pdf)". `CVPR 2019`[[code]](https://github.com/fengyang0317/unsupervised_captioning)

- :Yan Xu (UESTC); Baoyuan Wu (Tencent AI Lab)*; Fumin Shen (UESTC); Yanbo Fan (Tencent AI Lab); Yong Zhang (Tencent AI Lab); Heng Tao Shen (University of Electronic Science and Technology of China (UESTC)); Wei Liu (Tencent)  
"[Adversarial Attack to Image Captioning via Structured Output Learning With Latent Variables](http://openaccess.thecvf.com/content_CVPR_2019/papers/Xu_Exact_Adversarial_Attack_to_Image_Captioning_via_Structured_Output_Learning_CVPR_2019_paper.pdf)". `CVPR 2019` 

- :Qingzhong Wang (Department of Computer Science, City University of Hong Kong)*; Antoni Chan (City University of Hong Kong, Hong, Kong)  
"[Describing like Humans: On Diversity in Image Captioning](http://openaccess.thecvf.com/content_CVPR_2019/papers/Wang_Describing_Like_Humans_On_Diversity_in_Image_Captioning_CVPR_2019_paper.pdf)". `CVPR 2019` 

- :Longteng Guo ( Institute of Automation, Chinese Academy of Sciences)*; Jing Liu (National Lab of Pattern Recognition, Institute of Automation,Chinese Academy of Sciences); Peng Yao (University of Science and Technology Beijing); Jiangwei Li (Huawei); Hanqing Lu (NLPR, Institute of Automation, CAS)  
"[MSCap: Multi-Style Image Captioning With Unpaired Stylized Text](http://openaccess.thecvf.com/content_CVPR_2019/papers/Guo_MSCap_Multi-Style_Image_Captioning_With_Unpaired_Stylized_Text_CVPR_2019_paper.pdf)". `CVPR 2019`

- :Lu Zhang (Dalian University of Technology); Huchuan Lu (Dalian University of Technology)*; Zhe Lin (Adobe Research); Jianming Zhang (Adobe Research); You He (Naval Aviation University)  
"[CapSal: Leveraging Captioning to Boost Semantics for Salient Object Detection](http://openaccess.thecvf.com/content_CVPR_2019/papers/Zhang_CapSal_Leveraging_Captioning_to_Boost_Semantics_for_Salient_Object_Detection_CVPR_2019_paper.pdf)". `CVPR 2019` [[code]](https://github.com/zhangludl/code-and-dataset-for-CapSal)

- :Guojun Yin (University of Science and Technology of China); Lu Sheng (The Chinese University of Hong Kong)*; Bin Liu (University of Science and Technology of China); Nenghai Yu (University of Science and Technology of China); Xiaogang Wang (Chinese University of Hong Kong, Hong Kong); Jing Shao (Sensetime)  
"[Context and Attribute Grounded Dense Captioning](http://openaccess.thecvf.com/content_CVPR_2019/papers/Yin_Context_and_Attribute_Grounded_Dense_Captioning_CVPR_2019_paper.pdf)". `CVPR 2019`

- :Dong-Jin Kim (KAIST)*; Jinsoo Choi (KAIST); Tae-Hyun Oh (MIT CSAIL); In So Kweon (KAIST)  
"[Dense Relational Captioning: Triple-Stream Networks for Relationship-Based Captioning](http://openaccess.thecvf.com/content_CVPR_2019/papers/Kim_Dense_Relational_Captioning_Triple-Stream_Networks_for_Relationship-Based_Captioning_CVPR_2019_paper.pdf)". `CVPR 2019`

- :Marcella Cornia (University of Modena and Reggio Emilia); Lorenzo Baraldi (University of Modena and Reggio Emilia)*; Rita Cucchiara (Universita Di Modena E Reggio Emilia)  
"[Show, Control and Tell: A Framework for Generating Controllable and Grounded Captions](http://openaccess.thecvf.com/content_CVPR_2019/papers/Cornia_Show_Control_and_Tell_A_Framework_for_Generating_Controllable_and_CVPR_2019_paper.pdf)".. `CVPR 2019`

- :Junlong Gao (Peking University Shenzhen Graduate School)*; Shiqi Wang (CityU); Shanshe Wang (Peking University); Siwei Ma (Peking University, China); Wen Gao (PKU)  
"[Self-Critical N-step Training for Image Captioning](http://openaccess.thecvf.com/content_CVPR_2019/papers/Gao_Self-Critical_N-Step_Training_for_Image_Captioning_CVPR_2019_paper.pdf)". `CVPR 2019`

- :Yu Qin (Shanghai Jiao Tong University)*; Jiajun Du (Shanghai Jiao Tong University); Hongtao Lu (Shanghai Jiao Tong University); Yonghua Zhang (Bytedance)  
"[Look Back and Predict Forward in Image Captioning](http://openaccess.thecvf.com/content_CVPR_2019/papers/Qin_Look_Back_and_Predict_Forward_in_Image_Captioning_CVPR_2019_paper.pdf)". `CVPR 2019`

- :Yue Zheng (Tsinghua University); Ya-Li Li (THU); Shengjin Wang (Tsinghua University)*  
"[Intention Oriented Image Captions with Guiding Objects](http://openaccess.thecvf.com/content_CVPR_2019/papers/Zheng_Intention_Oriented_Image_Captions_With_Guiding_Objects_CVPR_2019_paper.pdf)". `CVPR 2019`

- :Pierre Dognin (IBM)*; Igor Melnyk (IBM); Youssef Mroueh (IBM Research); Jarret Ross (IBM); Tom Sercu (IBM Research AI)  
"[Adversarial Semantic Alignment for Improved Image Captions](http://openaccess.thecvf.com/content_CVPR_2019/papers/Dognin_Adversarial_Semantic_Alignment_for_Improved_Image_Captions_CVPR_2019_paper.pdf)". `CVPR 2019`

- :Ali Furkan Biten (Computer Vision Center)*; Lluis Gomez (Universitat Autónoma de Barcelona); Marçal Rusiñol (Computer Vision Center, UAB); Dimosthenis Karatzas (Computer Vision Centre)  
"[Good News, Everyone! Context driven entity-aware captioning for news images](http://openaccess.thecvf.com/content_CVPR_2019/papers/Biten_Good_News_Everyone_Context_Driven_Entity-Aware_Captioning_for_News_Images_CVPR_2019_paper.pdf)". `CVPR 2019` [[code]](https://github.com/furkanbiten/GoodNews)

- :Yehao Li (Sun Yat-Sen University); Ting Yao (JD AI Research); Yingwei Pan (JD AI Research)*; Hongyang Chao (Sun Yat-sen University); Tao Mei (AI Research of JD.com)  
"[Pointing Novel Objects in Image Captioning](http://openaccess.thecvf.com/content_CVPR_2019/papers/Li_Pointing_Novel_Objects_in_Image_Captioning_CVPR_2019_paper.pdf)". `CVPR 2019`

- :Kurt Shuster (Facebook)*; Samuel Humeau (Facebook); Hexiang Hu (USC); Antoine Bordes (Facebook); Jason Weston (FAIR)  
"[Engaging Image Captioning via Personality](http://openaccess.thecvf.com/content_CVPR_2019/papers/Shuster_Engaging_Image_Captioning_via_Personality_CVPR_2019_paper.pdf)". `CVPR 2019`
- :Yue Zheng, Yali Li, Shengjin Wang   
"[Intention Oriented Image Captions With Guiding Objects](http://openaccess.thecvf.com/content_CVPR_2019/papers/Zheng_Intention_Oriented_Image_Captions_With_Guiding_Objects_CVPR_2019_paper.pdf)". `CVPR 2019`
- :Yan Xu, Baoyuan Wu, Fumin Shen, Yanbo Fan, Yong Zhang, Heng Tao Shen, Wei Liu    
"[Exact Adversarial Attack to Image Captioning via Structured Output Learning With Latent Variables](http://openaccess.thecvf.com/content_CVPR_2019/papers/Xu_Exact_Adversarial_Attack_to_Image_Captioning_via_Structured_Output_Learning_CVPR_2019_paper.pdf)". `CVPR 2019`

**Video Captioning**
- **SDVC**:Jonghwan Mun (POSTECH)*; Linjie Yang (ByteDance AI Lab); Zhou Ren (Snap Inc.); Ning Xu (Snap); Bohyung Han (Seoul National University)  
"[Streamlined Dense Video Captioning](http://openaccess.thecvf.com/content_CVPR_2019/papers/Mun_Streamlined_Dense_Video_Captioning_CVPR_2019_paper.pdf)". `CVPR 2019 Oral`

- **GVD**:Luowei Zhou (University of Michigan)*; Yannis Kalantidis (Facebook Research); Xinlei Chen (Facebook AI Research); Jason J Corso (University of Michigan); Marcus Rohrbach (Facebook AI Research)  
"[Grounded Video Description](http://openaccess.thecvf.com/content_CVPR_2019/papers/Zhou_Grounded_Video_Description_CVPR_2019_paper.pdf)". `CVPR 2019 Oral`
  
- **HybridDis**:Jae Sung Park (UC Berkeley); Marcus Rohrbach (Facebook AI Research); Trevor Darrell (UC Berkeley); Anna Rohrbach (UC Berkeley)*	  
"[Adversarial Inference for Multi-Sentence Video Description](http://openaccess.thecvf.com/content_CVPR_2019/papers/Park_Adversarial_Inference_for_Multi-Sentence_Video_Description_CVPR_2019_paper.pdf)". `CVPR 2019 Oral`

- **OA-BTG**:Junchao Zhang (Peking University); Yuxin Peng (Peking University)*  
"[Object-aware Aggregation with Bidirectional Temporal Graph for Video Captioning](http://openaccess.thecvf.com/content_CVPR_2019/papers/Zhang_Object-Aware_Aggregation_With_Bidirectional_Temporal_Graph_for_Video_Captioning_CVPR_2019_paper.pdf)". `CVPR 2019`

- **MARN**:Wenjie Pei (Tencent)*; Jiyuan Zhang (Tencent YouTu); Xiangrong Wang (Delft University of Technology); Lei Ke (Tencent); Xiaoyong Shen (Tencent); Yu-Wing Tai (Tencent)  
"[Memory-Attended Recurrent Network for Video Captioning](http://openaccess.thecvf.com/content_CVPR_2019/papers/Pei_Memory-Attended_Recurrent_Network_for_Video_Captioning_CVPR_2019_paper.pdf)". `CVPR 2019`

- **GRU-EVE**:Nayyer Aafaq (The University of Western Australia)*; Naveed Akhtar (The University of Western Australia); Wei Liu (University of Western Australia); Syed Zulqarnain Gilani (The University of Western Australia); Ajmal Mian (University of Western Australia)  
"[Spatio-Temporal Dynamics and Semantic Attribute Enriched Visual Encoding for Video Captioning](http://openaccess.thecvf.com/content_CVPR_2019/papers/Aafaq_Spatio-Temporal_Dynamics_and_Semantic_Attribute_Enriched_Visual_Encoding_for_Video_CVPR_2019_paper.pdf)". `CVPR 2019`

## AAAI-2019
**Image Captioning**  
- 5123:CHEN CHEN (Tencent)*; SHUAI MU (Tencent); WANPENG XIAO (Tencent); ZEXIONG YE (Tencent); LIESI WU (Tencent); QI JU (Tencent)   
"[Improving Image Captioning with Conditional Generative Adversarial Nets](https://arxiv.org/pdf/1805.07112.pdf)". `AAAI 2019 Oral`

- 3934:Lingyun Song (Xi'an JiaoTong University)*; Jun Liu (Xi'an Jiaotong Univerisity); Buyue Qian (Xi'an Jiaotong University); Yihe Chen (University of Toronto)  
"[Connecting Language to Images: A Progressive Attention-Guided Network for Simultaneous Image Captioning and Language Grounding](https://www.aaai.org/ojs/index.php/AAAI/article/view/4916)". `AAAI 2019 Oral`

- 4938:Nannan Li (Wuhan University); Zhenzhong Chen (WHU)*; Shan Liu (Tencent America)  
"[Meta Learning for Image Captioning](https://www.aaai.org/ojs/index.php/AAAI/article/view/4883)". `AAAI 2019`

- 5390:Lianli Gao (The University of Electronic Science and Technology of China); kaixuan fan (University of Electronic Science and Technology of China); Jingkuan Song (UESTC); Xianglong Liu (Beihang University); Xing Xu (University of Electronic Science and Technology of China); Heng Tao Shen (University of Electronic Science and Technology of China (UESTC))*  
"[Deliberate Residual based Attention Network for Image Captioning](https://www.aaai.org/Papers/AAAI/2019/AAAI-GaoLianli3.5390.pdf)". `AAAI 2019`

- 1410:Weixuan Wang (School of Electronic and Information Engineering, Sun Yat-sen University); Zhihong Chen (School of Electronic and Information Engineering, Sun Yat-sen University); Haifeng Hu (School of Electronic and Information Engineering, Sun Yat-sen University)*   
"[Hierarchical Attention Network for Image Captioning](https://www.aaai.org/ojs/index.php/AAAI/article/view/4924)". `AAAI 2019`


**Video Captioning**  
- 1469:Xin Wang (University of California, Santa Barbara)*; Jiawei Wu (University of California, Santa Barbara); Da Zhang (UC Santa Barbara); Yu Su (OSU); William Wang (UC Santa Barbara)  
"[Learning to Compose Topic-Aware Mixture of Experts for Zero-Shot Video Captioning](https://arxiv.org/pdf/1811.02765.pdf)". `AAAI 2019 Oral`

- 2277:Jingwen Chen (Sun Yat-set University); Yingwei Pan (JD AI Research)*; Yehao Li (Sun Yat-Sen University); Ting Yao (JD AI Research); Hongyang Chao (Sun Yat-sen University); Tao Mei (AI Research of JD.com)  
"[Temporal Deformable Convolutional Encoder-Decoder Networks for Video Captioning](home.ustc.edu.cn/~panywei/paper/AAAI19.2277.pdf)". `AAAI 2019 Oral`

- 2389:Kuncheng Fang (Fudan University)*; Lian Zhou (Fudan University); Cheng Jin (Fudan University); Yuejie Zhang (Fudan University); Kangnian Weng (Shanghai University of Finance and Economics); Tao Zhang (Shanghai University of Finance and Economics); Weiguo Fan (University of Iowa)   
"[Fully Convolutional Video Captioning with Coarse-to-Fine and Inherited Attention](https://aaai.org/ojs/index.php/AAAI/article/view/4839)". `AAAI 2019`

- 2732:Shaoxiang Chen (Fudan University)*; Yu-Gang Jiang (Fudan University)  
"[Motion Guided Spatial Attention for Video Captioning](http://yugangjiang.info/publication/19AAAI-vidcaptioning.pdf)". `AAAI 2019`

- 3468:Xiangyang Li (Institute of Computing Technology, Chinese Academy of Sciences); Shuqiang Jiang (ICT, China Academy of Science)*; Jungong Han (Lancaster University)  
"[Learning Object Context for Dense Captioning](https://www.aaai.org/ojs/index.php/AAAI/article/view/4886)". `AAAI 2019` 



